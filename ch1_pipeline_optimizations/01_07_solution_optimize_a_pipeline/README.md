# 01_07 Solution: Optimize a Workflow in Bitbucket Pipelines

## Challenge Scenario

In this challenge you’re the Bitbucket Pipelines expert supporting development on the Amazing Mobile App.

The Data Analysis team has developed a Python script to run a cluster analysis. This script processes a large dataset stored in a JSON file and generates an analysis report.

The Data Analysis team is facing challenges with execution time and resource usage, and they’ve asked you to optimize their **Bitbucket Pipelines** workflow.

Specifically, they need a pipeline that:

1. Prevents the analysis from running more than 10 minutes
1. Minimizes the time spent loading data analysis libraries
1. Reuses any data that has already been generated by the script and written to the `./data` directory in the workspace
1. Only runs the analysis when the [cluster analysis](./cluster_analysis.py) script has changed.

Review the current pipeline configuration and make changes to optimize the pipeline as requested.

## Challenge Tasks

1. Log into Bitbucket and create a new repository.
1. Add the exercise files.
1. Run the pipeline to get an idea of the pipeline performance before making any changes.
1. Update the [pipeline configuration](./bitbucket-pipelines.yml) to meet the specifications provided by the Data Analysis team.

> [!NOTE]
> Use the topics from this chapter to solve the challenge, specifically: `max-time`, `caches`, and `conditions`.

This challenge should take 10-15 minutes to complete.

## Challenge Solution

1. Create a new repo and add the exercise files
1. Adding the files may not trigger the pipeline right away.  Go to the **Pipelines** menu and select **Run initial pipeline**.
1. When the pipeline completes, observe the **Step time duration**.
1. View and edit the pipeline configuration. Make the following changes:

  1. Add a `max-time` option:

          options:
            max-time: 10

  1. Add a custom cache definition for the `./data` directory:

          definitions:
            caches:
              data: ./data

  1. Update the step to use the custom cache and the pre-defined cache for `pip`.

          caches:
            - pip
            - data

1. Commit the changes and allow the pipeline to run.  This run should create the caches.
1. Observe the step time duration and confirm that the caches were created.
1. Select **Rerun** to run the pipeline again.
1. Observe the step time duration and confirm that the caches were downloaded.
1. Confirm that the installation used the cached content instead of downloading.
1. Confirm that the script used the local data instead of generating it.
1. View and edit the pipeline configuration. Make the following changes:

        condition:
          changesets:
            includePaths:
              - cluster_analysis.py

1. Commit the changes and allow the pipeline to run.
1. Observe the step time duration and confirm that the value is `0s`.

## Bonus steps

1. Make a small change to `cluster_analysis.py` and commit it to the repo.
1. Confirm that the script will run as expected when the code is updated.
1. Change the `max-time` value to 1.  Update the `cluster_analysis.py` script and commit the changes.
1. Confirm the pipeline terminates if the `max-time` value is exceeded.

The final pipeline configuration should be similar to the following [bitbucket-pipelines.yml](./bitbucket-pipelines.yml) file:

```yaml
image: python:3.12

options:
  max-time: 10

definitions:
  caches:
    data: ./data

pipelines:
  default:
    - step:
        name: Run Data Analysis

        caches:
          - pip
          - data

        condition:
          changesets:
            includePaths:
              - cluster_analysis.py

        script:
          - pip install -r requirements.txt
          - python cluster_analysis.py

        artifacts:
          - analysis_report.md
```

<!-- FooterStart -->
---
[← 01_06 Challenge: Optimize a Workflow in Bitbucket Pipelines](../01_06_challenge_optimize_a_pipeline/README.md) | [02_01 Getting to Know Pipes →](../../ch2_using_pipes_in_pipelines/02_01_getting_to_know_pipes/README.md)
<!-- FooterEnd -->
